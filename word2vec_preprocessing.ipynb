{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nKernel: Preprocessing when using embeddings.\\nTwo golden rules:\\n1. Don't use standard preprocessing steps like stemming or stopword removal \\n   when you have pre-trained embeddings.\\n   (Some of you might used standard preprocessing steps when doing word \\n   count based feature extraction (e.g. TFIDF) such as removing stopwords, \\n   stemming etc. The reason is simple: You loose valuable information, \\n   which would help your NN to figure things out.)\\n2. Get your vocabulary as close to the embeddings as possible.\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Kernel: Preprocessing when using embeddings.\n",
    "Two golden rules:\n",
    "1. Don't use standard preprocessing steps like stemming or stopword removal \n",
    "   when you have pre-trained embeddings.\n",
    "   (Some of you might used standard preprocessing steps when doing word \n",
    "   count based feature extraction (e.g. TFIDF) such as removing stopwords, \n",
    "   stemming etc. The reason is simple: You loose valuable information, \n",
    "   which would help your NN to figure things out.)\n",
    "2. Get your vocabulary as close to the embeddings as possible.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"./data/train.csv\"\n",
    "test_data_path = \"./data/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_data_path)\n",
    "test_df = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00014894849d00ba98a9</td>\n",
       "      <td>My voice range is A2-C5. My chest voice goes u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000156468431f09b3cae</td>\n",
       "      <td>How much does a tutor earn in Bangalore?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000227734433360e1aae</td>\n",
       "      <td>What are the best made pocket knives under $20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0005e06fbe3045bd2a92</td>\n",
       "      <td>Why would they add a hypothetical scenario tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00068a0f7f41f50fc399</td>\n",
       "      <td>What is the dresscode for Techmahindra freshers?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text\n",
       "0  00014894849d00ba98a9  My voice range is A2-C5. My chest voice goes u...\n",
       "1  000156468431f09b3cae           How much does a tutor earn in Bangalore?\n",
       "2  000227734433360e1aae  What are the best made pocket knives under $20...\n",
       "3  0005e06fbe3045bd2a92  Why would they add a hypothetical scenario tha...\n",
       "4  00068a0f7f41f50fc399   What is the dresscode for Techmahindra freshers?"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape:  (1306122, 3)\n",
      "test data shape:  (56370, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"train data shape: \", train_df.shape)\n",
    "print(\"test data shape: \", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集，验证集\n",
    "train_df, val_df = train_test_split(train_df, \n",
    "                                    test_size=0.1, \n",
    "                                    train_size=0.9,\n",
    "                                    random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape:  (1175509, 3)\n",
      "val data shape:  (130613, 3)\n",
      "test data shape:  (56370, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"train data shape: \", train_df.shape)\n",
    "print(\"val data shape: \", val_df.shape)\n",
    "print(\"test data shape: \", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 缺失值填充\n",
    "train_df[\"question_text\"].fillna(\"_na_\", inplace=True)\n",
    "val_df[\"question_text\"].fillna(\"_na_\", inplace=True)\n",
    "test_df[\"question_text\"].fillna(\"_na_\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1306122,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 整个训练语料文本\n",
    "all_data_text = pd.concat([train_df['question_text'], val_df['question_text']], axis=0)\n",
    "all_data_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立词表\n",
    "def build_vocab(sentences):\n",
    "    # sentences: list of list of words\n",
    "    # return: dictionary of words in training corpus\n",
    "    vocab = {}\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            if word not in vocab:\n",
    "                vocab[word] = len(vocab)\n",
    "    return vocab\n",
    "# 统计词表词频\n",
    "def build_vocab_count(sentences):\n",
    "    # sentences: list of list of words\n",
    "    # return: dictionary of words and their count\n",
    "    vocab_count = {}\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            if word in vocab_count:\n",
    "                vocab_count[word] += 1\n",
    "            else:\n",
    "                vocab_count[word] = 1\n",
    "    return vocab_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = all_data_text.apply(lambda x: x.split()).values\n",
    "# 生成词表dict，和词表与其对应的词频dict\n",
    "vocab = build_vocab(sentences)\n",
    "vocab_count = build_vocab_count(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intereview': 1, 'posioned?': 1, 'Genji': 6, 'hourly.': 1, 'Anaheim': 3, '\"நான்': 1, 'Statups': 1, 'directing': 35, \"Doll's\": 4, 'opposite)': 1}\n"
     ]
    }
   ],
   "source": [
    "print({k: vocab_count[k] for k in list(vocab_count)[:10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取Google预训练的词向量word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "word_embedding_path = './word embedding/GoogleNews-vectors-negative300.bin'\n",
    "embedding_dict = KeyedVectors.load_word2vec_format(word_embedding_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"##V\" in embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计未登录词\n",
    "def check_out_of_vocab(vocab_count, embedding_dict):\n",
    "    exist_word = {}\n",
    "    oov_word = {}\n",
    "    exist_count = 0    # 包含在word2vec中的词频的总数\n",
    "    oov_count = 0      # 未登录词的词频总数\n",
    "    for word in vocab_count:\n",
    "        if word in embedding_dict:\n",
    "            exist_word[word] = embedding_dict[word]\n",
    "            exist_count += vocab_count[word]\n",
    "        else:\n",
    "            oov_word[word] = vocab_count[word]\n",
    "            oov_count += vocab_count[word]\n",
    "    print('{:.2%} words of vocab founded in word2vec.'.format(len(exist_word) / len(vocab_count)))\n",
    "    print('{:.2%} words of all text founded in word2vec.'.format(exist_count / (exist_count + oov_count)))\n",
    "    sorted_oov_word = sorted(oov_word.items(), key=lambda x: x[1])[::-1]\n",
    "    return sorted_oov_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.31% words of vocab founded in word2vec.\n",
      "78.75% words of all text founded in word2vec.\n"
     ]
    }
   ],
   "source": [
    "oov_word = check_out_of_vocab(vocab_count, embedding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 403183),\n",
       " ('a', 402682),\n",
       " ('of', 330825),\n",
       " ('and', 251973),\n",
       " ('India?', 16384),\n",
       " ('it?', 12900),\n",
       " ('do?', 8753),\n",
       " ('life?', 7753),\n",
       " ('you?', 6295),\n",
       " ('me?', 6202)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov_word[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n直接按空格符进行分词，未经过任何处理时，只有24%的词有预训练的词向量，\\n然后，根据以上打印出的oov_word中的词, 说明：\\n很多句子结尾的词，与问号之间没有空格符隔开，被当做一个词了，所以在预训练的word2vec中找不到。\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "直接按空格符进行分词，未经过任何处理时，只有24%的词有预训练的词向量，\n",
    "然后，根据以上打印出的oov_word中的词, 说明：\n",
    "很多句子结尾的词，与问号之间没有空格符隔开，被当做一个词了，所以在预训练的word2vec中找不到。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n在处理punctuation时，如果预训练的词向量中有这个符号，则保留，如果没有则去除该符号.\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "在处理punctuation时，如果预训练的词向量中有这个符号，则保留，如果没有则去除该符号.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print('?' in embedding_dict)    # '?'在word2vec中吗？不在\n",
    "print('.' in embedding_dict)\n",
    "print('&' in embedding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all punctuations:  !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "exist punctuations:  #$%&*+=>@^_`~\n",
      "oov punctuations:  !\"'(),-./:;<?[\\]{|}\n"
     ]
    }
   ],
   "source": [
    "exist_punc = \"\"    # 有预训练的词向量的符号\n",
    "oov_punc = \"\"      # 没有预训练词向量的符号\n",
    "all_punctuation = string.punctuation\n",
    "print('all punctuations: ', all_punctuation)\n",
    "for punc in all_punctuation:\n",
    "    if punc in embedding_dict:\n",
    "        exist_punc += punc\n",
    "    else:\n",
    "        oov_punc += punc\n",
    "print('exist punctuations: ', exist_punc)\n",
    "print('oov punctuations: ', oov_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理语料中的标点符号\n",
    "def clean_punctuation(sent):\n",
    "    sent = str(sent)\n",
    "    for punc in \"/-\":\n",
    "        sent = sent.replace(punc, ' ')\n",
    "    for punc in exist_punc:\n",
    "        sent = sent.replace(punc, ' '+punc+' ')\n",
    "    for punc in oov_punc + \"”“‘’\":\n",
    "        sent = sent.replace(punc, '')\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.29% words of vocab founded in word2vec.\n",
      "89.80% words of all text founded in word2vec.\n"
     ]
    }
   ],
   "source": [
    "all_data_text = all_data_text.apply(lambda x: clean_punctuation(x))\n",
    "sentences = all_data_text.apply(lambda x: x.split())\n",
    "vocab = build_vocab(sentences)\n",
    "vocab_count = build_vocab_count(sentences)\n",
    "oov_word = check_out_of_vocab(vocab_count, embedding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n处理完标点符号之后，现在词表中有58%的词有预训练的词向量了\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "处理完标点符号之后，现在词表中有58%的词有预训练的词向量了\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 406304),\n",
       " ('a', 404284),\n",
       " ('of', 332972),\n",
       " ('and', 254088),\n",
       " ('2017', 8789),\n",
       " ('2018', 7372),\n",
       " ('10', 6852),\n",
       " ('doesnt', 6780),\n",
       " ('didnt', 3879),\n",
       " ('12', 3741)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov_word[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n再次打印出oov word，可以看出，词表中存在大量数字，这些数字全都没有预训练的词向量，\\n词表中数字的处理：\\n在word2vec中，只包含0-9十个数字的词向量，其他所有大于9的数字都被特殊字符替代，\\n例如，15 ——> ##， 123 ——> ###,  15.80$ --> ##.##$\\n所以我们对语料也进行相同的处理.\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "再次打印出oov word，可以看出，词表中存在大量数字，这些数字全都没有预训练的词向量，\n",
    "词表中数字的处理：\n",
    "在word2vec中，只包含0-9十个数字的词向量，其他所有大于9的数字都被特殊字符替代，\n",
    "例如，15 ——> ##， 123 ——> ###,  15.80$ --> ##.##$\n",
    "所以我们对语料也进行相同的处理.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_number(sent):\n",
    "    sent = re.sub('[0-9]{5,}', '#####', sent)\n",
    "    sent = re.sub('[0-9]{4}', '####', sent)\n",
    "    sent = re.sub('[0-9]{3}', '###', sent)\n",
    "    sent = re.sub('[0-9]{2}', '##', sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.19% words of vocab founded in word2vec.\n",
      "90.58% words of all text founded in word2vec.\n"
     ]
    }
   ],
   "source": [
    "all_data_text = all_data_text.apply(lambda x: clean_number(x))\n",
    "sentences = all_data_text.apply(lambda x: x.split())\n",
    "vocab = build_vocab(sentences)\n",
    "vocab_count = build_vocab_count(sentences)\n",
    "oov_word = check_out_of_vocab(vocab_count, embedding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 406304),\n",
       " ('a', 404284),\n",
       " ('of', 332972),\n",
       " ('and', 254088),\n",
       " ('doesnt', 6780),\n",
       " ('didnt', 3879),\n",
       " ('isnt', 2790),\n",
       " ('Isnt', 1429),\n",
       " ('favourite', 1246),\n",
       " ('bitcoin', 980),\n",
       " ('colour', 976),\n",
       " ('centre', 884),\n",
       " ('Quorans', 879),\n",
       " ('cryptocurrency', 820),\n",
       " ('shouldnt', 797),\n",
       " ('Snapchat', 785),\n",
       " ('hasnt', 784),\n",
       " ('wasnt', 743),\n",
       " ('travelling', 705),\n",
       " ('btech', 634)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov_word[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n根据现在的oov word，我们可以考虑去掉'to', 'a', 'of', 'and'这四个单词，\\n然后进行一些常见的错别字替换。\\n\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "根据现在的oov word，我们可以考虑去掉'to', 'a', 'of', 'and'这四个单词，\n",
    "然后进行一些常见的错别字替换。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 人工定义一个常见错别字词典：\n",
    "mis_spell_dict = {'colour':'color',\n",
    "                  'centre':'center',\n",
    "                  'didnt':'did not',\n",
    "                  'doesnt':'does not',\n",
    "                  'isnt':'is not',\n",
    "                  'shouldnt':'should not',\n",
    "                  'favourite':'favorite',\n",
    "                  'travelling':'traveling',\n",
    "                  'counselling':'counseling',\n",
    "                  'theatre':'theater',\n",
    "                  'cancelled':'canceled',\n",
    "                  'labour':'labor',\n",
    "                  'organisation':'organization',\n",
    "                  'wwii':'world war 2',\n",
    "                  'citicise':'criticize',\n",
    "                  'instagram': 'social medium',\n",
    "                  'whatsapp': 'social medium',\n",
    "                  'snapchat': 'social medium'\n",
    "                 }\n",
    "\n",
    "# 人工定义需要去掉的停用词：\n",
    "need_remove_words = ['a', 'to', 'of', 'and']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_mis_spell(sent):\n",
    "    for key, value in mis_spell_dict.items():\n",
    "        sent = sent.replace(key, value)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.20% words of vocab founded in word2vec.\n",
      "98.90% words of all text founded in word2vec.\n"
     ]
    }
   ],
   "source": [
    "all_data_text = all_data_text.apply(lambda x: clean_mis_spell(x))\n",
    "sentences = all_data_text.apply(lambda x: x.split())\n",
    "sentences = [[word for word in sent if not word in need_remove_words] for sent in sentences]\n",
    "vocab = build_vocab(sentences)\n",
    "vocab_count = build_vocab_count(sentences)\n",
    "oov_word = check_out_of_vocab(vocab_count, embedding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n现在词典中有61%种词有预训练的词向量，\\n整个训练文本中99%的词都有预训练的词向量。\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "现在词典中有61%种词有预训练的词向量，\n",
    "整个训练文本中99%的词都有预训练的词向量。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Isnt', 1429),\n",
       " ('bitcoin', 980),\n",
       " ('Quorans', 879),\n",
       " ('cryptocurrency', 820),\n",
       " ('Snapchat', 785),\n",
       " ('hasnt', 784),\n",
       " ('wasnt', 743),\n",
       " ('btech', 634),\n",
       " ('Brexit', 492),\n",
       " ('cryptocurrencies', 481),\n",
       " ('Shouldnt', 477),\n",
       " ('blockchain', 474),\n",
       " ('behaviour', 468),\n",
       " ('upvotes', 433),\n",
       " ('programme', 401),\n",
       " ('Doesnt', 381),\n",
       " ('Redmi', 378),\n",
       " ('realise', 371),\n",
       " ('defence', 364),\n",
       " ('KVPY', 349)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov_word[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245551"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
